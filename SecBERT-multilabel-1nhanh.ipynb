{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"5McNPOlukgPY"},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics import *\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import torch.nn as nn\n","import torch\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import time\n","import matplotlib\n","import gc\n","from transformers import BertForSequenceClassification, BertTokenizerFast\n","matplotlib.use('Agg')"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["20"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.empty_cache()\n","gc.collect()\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Set data folder and sample size\n","data_folder = os.getcwd() + '/Untitled Folder/'\n","n_samples = 20"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["X_train = pd.read_csv(data_folder+'X_train.csv').sample(n_samples)\n","X_test = pd.read_csv(data_folder+'X_test.csv').sample(n_samples)\n","X_val = pd.read_csv(data_folder+'X_val.csv').sample(n_samples)\n","\n","y_train = pd.read_csv(data_folder+'y_train.csv').sample(n_samples).to_numpy()\n","y_test = pd.read_csv(data_folder+'y_test.csv').sample(n_samples).to_numpy()\n","y_val = pd.read_csv(data_folder+'y_val.csv').sample(n_samples).to_numpy()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Set model parameters\n","max_length = 512\n","TRAIN_BATCH_SIZE = 16\n","VALID_BATCH_SIZE = 16\n","EPOCHS = 1\n","LEARNING_RATE = 1e-04\n","num_class = 4\n","labels = ['Timestamp dependence', 'Outdated Solidity version',\n","          'Frozen Ether', 'Delegatecall Injection']"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at jackaduma/SecBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Load pre-trained tokenizer and model\n","secBertTokenizer = BertTokenizerFast.from_pretrained(\"jackaduma/SecBERT\", do_lower_case=True)\n","secBertClassifier = BertForSequenceClassification.from_pretrained(\"jackaduma/SecBERT\", num_labels=num_class)\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Freeze layers\n","for param in secBertClassifier.bert.encoder.layer[0:4].parameters():\n","    param.requires_grad = False"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Custom classifier module\n","class CustomClassifier(nn.Module):\n","    def __init__(self, original_model):\n","        super(CustomClassifier, self).__init__()\n","        self.original_model = original_model\n","        self.activation = nn.Sigmoid()\n","\n","    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n","        outputs = self.original_model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, labels=labels)\n","        logits = self.activation(outputs.logits)\n","        return logits\n","\n","secBertClassifierMultilabel = CustomClassifier(secBertClassifier)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Dataset class\n","class OpcodeData(Dataset):\n","    def __init__(self, X, y, tokenizer, max_len):\n","        self.tokenizer = tokenizer\n","        self.X = X.to_numpy()\n","        self.targets = y\n","        self.max_len = max_len\n","        self.tfidf = TfidfVectorizer(max_features=256)\n","        self.matrix = self.tfidf.fit_transform(X['BYTECODE'])\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, index):\n","        values = self.X[index]\n","        for value in values:\n","            text = value\n","        inputs = self.tokenizer(text, None, truncation=True, padding='max_length',\n","                                add_special_tokens=True, max_length=self.max_len, return_token_type_ids=True)\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        token_type_ids = inputs[\"token_type_ids\"]\n","        tfidf_features = self.matrix[index].todense()\n","        return {\n","            'index': index,\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'tfidf_features': torch.tensor(tfidf_features, dtype=torch.float),\n","            'targets': torch.tensor(self.targets[index], dtype=torch.long)\n","        }"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Create datasets and loaders\n","training_set = OpcodeData(X_train, y_train, secBertTokenizer, max_length)\n","validating_set = OpcodeData(X_val, y_val, secBertTokenizer, max_length)\n","testing_set = OpcodeData(X_test, y_test, secBertTokenizer, max_length)\n","\n","training_loader = DataLoader(training_set, batch_size=TRAIN_BATCH_SIZE)\n","validating_loader = DataLoader(validating_set, batch_size=VALID_BATCH_SIZE)\n","testing_loader = DataLoader(testing_set, batch_size=VALID_BATCH_SIZE)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def save_classification(y_test, y_pred, out_dir, labels):\n","    def accuracy(y_true, y_pred):\n","        temp = 0\n","        for i in range(len(y_true)):\n","            numerator = sum(np.logical_and(y_true[i], y_pred[i]))\n","            denominator = sum(np.logical_or(y_true[i], y_pred[i]))\n","            if denominator != 0:\n","                temp += numerator / denominator\n","        return temp / len(y_true)\n","\n","    out = classification_report(\n","        y_test, y_pred, output_dict=True, target_names=labels)\n","    total_support = out['samples avg']['support']\n","    mr = accuracy_score(y_test, y_pred)\n","    acc = accuracy(y_test, y_pred)\n","    hm = hamming_loss(y_test, y_pred)\n","\n","    out['Exact Match Ratio'] = {\n","        'precision': mr, 'recall': mr, 'f1-score': mr, 'support': total_support}\n","    out['Hamming Loss'] = {'precision': hm, 'recall': hm,\n","                           'f1-score': hm, 'support': total_support}\n","    out['Accuracy'] = {'precision': acc, 'recall': acc,\n","                       'f1-score': acc, 'support': total_support}\n","    out_df = pd.DataFrame(out).transpose()\n","    print(out_df)\n","    out_df.to_csv(out_dir)\n","    return out_df"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def calculate_score(y_true, preds):\n","    F1_score = f1_score(y_true, preds, average='macro')\n","    acc_score = accuracy_score(y_true, preds)\n","    return acc_score, F1_score"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def train_steps(training_loader, model, loss_f, optimizer):\n","    print('Training...')\n","    training_loss = 0\n","    n_correct = 0\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","    train_acc = 0.\n","    train_f1 = 0.\n","    model.train()\n","    for step, batch in enumerate(training_loader):\n","        ids = batch['ids'].to(device)\n","        mask = batch['mask'].to(device)\n","        token_type_ids = batch['token_type_ids'].to(device)\n","        targets = batch['targets'].to(\n","            device).float()  # Convert targets to float\n","        preds = model(ids, attention_mask=mask, token_type_ids=token_type_ids)\n","        loss = loss_f(preds, targets)\n","        training_loss += loss.item()\n","        preds = preds.detach().cpu().numpy()\n","        preds = np.where(preds >= 0.5, 1, 0)\n","        label_ids = targets.to('cpu').numpy()\n","        acc_score = accuracy_score(label_ids, preds)\n","        train_acc += acc_score\n","        nb_tr_steps += 1\n","        optimizer.zero_grad()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","    epoch_loss = training_loss / nb_tr_steps\n","    epoch_acc = train_acc / nb_tr_steps\n","    return epoch_loss, epoch_acc"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def evaluate_steps(validating_loader, model, loss_f):\n","    print(\"\\nEvaluating...\")\n","    model.eval()\n","    total_loss, total_accuracy = 0, 0\n","    total_preds = []\n","    total_labels = []\n","    for step, batch in enumerate(validating_loader):\n","        b_input_ids = batch['ids'].to(device)\n","        b_input_mask = batch['mask'].to(device)\n","        token_type_ids = batch['token_type_ids'].to(device)\n","        b_labels = batch['targets'].to(\n","            device).float()  # Convert targets to float\n","        with torch.no_grad():\n","            preds = model(b_input_ids, attention_mask=b_input_mask,\n","                          token_type_ids=token_type_ids)\n","            loss = loss_f(preds, b_labels)\n","\n","            total_loss = total_loss + loss.item()\n","\n","            preds = preds.detach().cpu().numpy()\n","            preds = np.where(preds >= 0.5, 1, 0)\n","            total_preds += list(preds)\n","            total_labels += b_labels.tolist()\n","    avg_loss = total_loss / len(validating_loader)\n","    acc_score = accuracy_score(total_labels, total_preds)\n","    return avg_loss, acc_score"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def predict(testing_loader, model):\n","    print(\"\\nEvaluating...\")\n","    model.eval()\n","    total_preds = []\n","    total_labels = []\n","    for step, batch in enumerate(testing_loader):\n","        b_input_ids = batch['ids'].to(device)\n","        b_input_mask = batch['mask'].to(device)\n","        token_type_ids = batch['token_type_ids'].to(device)\n","        targets = batch['targets'].to(device)\n","        with torch.no_grad():\n","            preds = model(b_input_ids, attention_mask=b_input_mask,\n","                          token_type_ids=token_type_ids).float()\n","            preds = preds.detach().cpu().numpy()\n","            preds = np.where(preds >= 0.5, 1, 0)\n","            total_preds += list(preds)\n","            total_labels += targets.tolist()\n","    return total_labels, total_preds"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["def train(epochs, model, optimizer, criterion, dataloader):\n","    data_train_loader, data_val_loader = dataloader\n","    best_valid_loss = float('inf')\n","    train_losses = []\n","    valid_losses = []\n","    train_accuracies = []\n","    valid_accuracies = []\n","    for epoch in range(epochs):\n","        print('Epoch {}/{} '.format(epoch + 1, epochs))\n","        start_time = time.time()\n","        train_loss, train_acc = train_steps(\n","            data_train_loader, model, criterion, optimizer)\n","        valid_loss, valid_acc = evaluate_steps(\n","            data_val_loader, model, criterion)\n","        if valid_loss < best_valid_loss:\n","            best_valid_loss = valid_loss\n","            torch.save(model.state_dict(), 'multilabel-lstm.pt')\n","        train_losses.append(train_loss)\n","        valid_losses.append(valid_loss)\n","        train_accuracies.append(train_acc)\n","        valid_accuracies.append(valid_acc)\n","        elapsed_time = time.time() - start_time\n","        print('\\t loss={:.4f} \\t accuracy={:.4f} \\t val_loss={:.4f}  \\t val_acc={:.4f}  \\t time={:.2f}s'.format(\n","            train_loss, train_acc, valid_loss, valid_acc, elapsed_time))\n","    return train_accuracies, valid_accuracies, train_losses, valid_losses"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["def plot_graph(epochs, train, valid, tittle):\n","    fig = plt.figure(figsize=(12, 12))\n","    plt.title(tittle)\n","    plt.plot(list(np.arange(epochs) + 1), train, label='train')\n","    plt.plot(list(np.arange(epochs) + 1), valid, label='validation')\n","    plt.xlabel('num_epochs', fontsize=12)\n","    plt.ylabel('loss', fontsize=12)\n","    plt.legend(loc='best')"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# Set model and optimizer\n","secBertClassifierMultilabel.to(device)\n","optimizer = torch.optim.Adam(params=secBertClassifierMultilabel.parameters(), lr=LEARNING_RATE)\n","criterion = nn.BCEWithLogitsLoss()"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/1 \n","Training...\n","\n","Evaluating...\n","\t loss=0.7340 \t accuracy=0.0312 \t val_loss=0.6918  \t val_acc=0.1000  \t time=3.73s\n"]}],"source":["# Train the model\n","train_accuracies, valid_accuracies, train_losses, valid_losses = train(EPOCHS, secBertClassifierMultilabel, optimizer, criterion, (training_loader, validating_loader))"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# Plot graphs\n","plot_graph(EPOCHS, train_losses, valid_losses, \"Train/Validation Loss\")\n","plot_graph(EPOCHS, train_accuracies, valid_accuracies, \"Train/Validation Accuracy\")\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Evaluating...\n","                           precision    recall  f1-score  support\n","Timestamp dependence        0.000000  0.000000  0.000000      0.0\n","Outdated Solidity version   1.000000  0.650000  0.787879     20.0\n","Frozen Ether                0.750000  0.600000  0.666667     15.0\n","Delegatecall Injection      0.000000  0.000000  0.000000      0.0\n","micro avg                   0.564103  0.628571  0.594595     35.0\n","macro avg                   0.437500  0.312500  0.363636     35.0\n","weighted avg                0.892857  0.628571  0.735931     35.0\n","samples avg                 0.575000  0.650000  0.578333     35.0\n","Exact Match Ratio           0.000000  0.000000  0.000000     35.0\n","Hamming Loss                0.375000  0.375000  0.375000     35.0\n","Accuracy                    0.425000  0.425000  0.425000     35.0\n"]},{"name":"stderr","output_type":"stream","text":["/home/bkcs/miniconda3/envs/secbert/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Timestamp dependence</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>Outdated Solidity version</th>\n","      <td>1.000000</td>\n","      <td>0.650000</td>\n","      <td>0.787879</td>\n","      <td>20.0</td>\n","    </tr>\n","    <tr>\n","      <th>Frozen Ether</th>\n","      <td>0.750000</td>\n","      <td>0.600000</td>\n","      <td>0.666667</td>\n","      <td>15.0</td>\n","    </tr>\n","    <tr>\n","      <th>Delegatecall Injection</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>micro avg</th>\n","      <td>0.564103</td>\n","      <td>0.628571</td>\n","      <td>0.594595</td>\n","      <td>35.0</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.437500</td>\n","      <td>0.312500</td>\n","      <td>0.363636</td>\n","      <td>35.0</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.892857</td>\n","      <td>0.628571</td>\n","      <td>0.735931</td>\n","      <td>35.0</td>\n","    </tr>\n","    <tr>\n","      <th>samples avg</th>\n","      <td>0.575000</td>\n","      <td>0.650000</td>\n","      <td>0.578333</td>\n","      <td>35.0</td>\n","    </tr>\n","    <tr>\n","      <th>Exact Match Ratio</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>35.0</td>\n","    </tr>\n","    <tr>\n","      <th>Hamming Loss</th>\n","      <td>0.375000</td>\n","      <td>0.375000</td>\n","      <td>0.375000</td>\n","      <td>35.0</td>\n","    </tr>\n","    <tr>\n","      <th>Accuracy</th>\n","      <td>0.425000</td>\n","      <td>0.425000</td>\n","      <td>0.425000</td>\n","      <td>35.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                           precision    recall  f1-score  support\n","Timestamp dependence        0.000000  0.000000  0.000000      0.0\n","Outdated Solidity version   1.000000  0.650000  0.787879     20.0\n","Frozen Ether                0.750000  0.600000  0.666667     15.0\n","Delegatecall Injection      0.000000  0.000000  0.000000      0.0\n","micro avg                   0.564103  0.628571  0.594595     35.0\n","macro avg                   0.437500  0.312500  0.363636     35.0\n","weighted avg                0.892857  0.628571  0.735931     35.0\n","samples avg                 0.575000  0.650000  0.578333     35.0\n","Exact Match Ratio           0.000000  0.000000  0.000000     35.0\n","Hamming Loss                0.375000  0.375000  0.375000     35.0\n","Accuracy                    0.425000  0.425000  0.425000     35.0"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# Predict and save results\n","y_preds, total_test = predict(testing_loader, secBertClassifierMultilabel)\n","save_classification(y_test=total_test, y_pred=y_preds, labels=labels, out_dir='secbert-multilabel.csv')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"046a26a38cbf4a8da47615a2858a7eba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"098b7ae2e5db47fcb0b40422bf052132":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b018742630a0454b8fda01d7af9042be","IPY_MODEL_8626c81cb5bd41f1ba09528e82729539","IPY_MODEL_bf1945d5fa0b4a3183f97b126dd275a6"],"layout":"IPY_MODEL_ce960736220f44e38746d66fc6ba5988"}},"0bd7292d7c264a03aa71e92c81842a13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22688d56fb5a436c838ea9e1c6d51194":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6b5c14e36584349b8027e8cd4037388","placeholder":"​","style":"IPY_MODEL_a8e51a8058f649c5af3a5524286dd69c","value":" 378k/378k [00:00&lt;00:00, 4.00MB/s]"}},"2e6dc0393d664e6faa7b8e48788f8cb0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39c9e74a36874c08b648fd1cf45e37a9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"458754914dce441d9b0d07c8f103854e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4764d42eb4c9431fa5d588675de41090":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62d37120dad040559c01167b2292e7a0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"721cf045ea764126b4434369a2cdce6c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"738427ae21c04911bce56d5a0e44a330":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7ed56f8046c42258c07178054d9f99c","max":378000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d562d10d1408441bb461526905874d11","value":378000}},"7d2d0f62303a49ad8e8aa5df38e43c16":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39c9e74a36874c08b648fd1cf45e37a9","placeholder":"​","style":"IPY_MODEL_458754914dce441d9b0d07c8f103854e","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"80b7fadd0deb48819fbf0aeec8bdd481":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8626c81cb5bd41f1ba09528e82729539":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bd7292d7c264a03aa71e92c81842a13","max":467,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d35066a0a935438997d03b60dab3d81d","value":467}},"a8e51a8058f649c5af3a5524286dd69c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad50c702fcab4297a4060854852ed742":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b018742630a0454b8fda01d7af9042be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddda5629b1244e379e5fb2ec3b1cba3d","placeholder":"​","style":"IPY_MODEL_df0166221362437b8effc94687c7c0f9","value":"Downloading (…)lve/main/config.json: 100%"}},"b12f54ae2c0b41fc98cb38c5dc42ba6e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_62d37120dad040559c01167b2292e7a0","max":336396808,"min":0,"orientation":"horizontal","style":"IPY_MODEL_80b7fadd0deb48819fbf0aeec8bdd481","value":336396808}},"b7ed56f8046c42258c07178054d9f99c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf1945d5fa0b4a3183f97b126dd275a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb239b47aa4b412eb425312d6de2f2e9","placeholder":"​","style":"IPY_MODEL_f0c67f8ca43b4cebb6dc9fa7c3841be9","value":" 467/467 [00:00&lt;00:00, 16.2kB/s]"}},"c6b5c14e36584349b8027e8cd4037388":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb239b47aa4b412eb425312d6de2f2e9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce960736220f44e38746d66fc6ba5988":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d35066a0a935438997d03b60dab3d81d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d562d10d1408441bb461526905874d11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"db00a264c734455b8fb099886736a422":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddda5629b1244e379e5fb2ec3b1cba3d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df0166221362437b8effc94687c7c0f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e52ed411871f401aa1a700ca978d1540":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_721cf045ea764126b4434369a2cdce6c","placeholder":"​","style":"IPY_MODEL_2e6dc0393d664e6faa7b8e48788f8cb0","value":"Downloading model.safetensors: 100%"}},"f0c67f8ca43b4cebb6dc9fa7c3841be9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5ee8a9e38d4462692816b68a857561e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_046a26a38cbf4a8da47615a2858a7eba","placeholder":"​","style":"IPY_MODEL_ad50c702fcab4297a4060854852ed742","value":" 336M/336M [00:03&lt;00:00, 89.8MB/s]"}},"fb5bc4be10aa460b9ce97d152344c2d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e52ed411871f401aa1a700ca978d1540","IPY_MODEL_b12f54ae2c0b41fc98cb38c5dc42ba6e","IPY_MODEL_f5ee8a9e38d4462692816b68a857561e"],"layout":"IPY_MODEL_4764d42eb4c9431fa5d588675de41090"}},"ff0f657991ab47e09e5c6c08d7b9ba8b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d2d0f62303a49ad8e8aa5df38e43c16","IPY_MODEL_738427ae21c04911bce56d5a0e44a330","IPY_MODEL_22688d56fb5a436c838ea9e1c6d51194"],"layout":"IPY_MODEL_db00a264c734455b8fb099886736a422"}}}}},"nbformat":4,"nbformat_minor":0}
