{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "5McNPOlukgPY"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torchvision.models.alexnet import AlexNet_Weights\n",
    "import torch\n",
    "import csv\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import collections\n",
    "import cv2\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import time\n",
    "import matplotlib\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import PIL.Image\n",
    "\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "rW69pATPbH90",
    "outputId": "9f822a2e-2506-4cb0-d4a1-50bd0031e49a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "device = torch.device(dev)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.getcwd()+'/Untitled Folder/'\n",
    "\n",
    "# X_train = pd.read_csv(data_folder+'X_train.csv')\n",
    "# X_test = pd.read_csv(data_folder+'X_test.csv')\n",
    "# X_val = pd.read_csv(data_folder+'X_val.csv')\n",
    "\n",
    "# y_train = pd.read_csv(data_folder+'y_train.csv').to_numpy()\n",
    "# y_test = pd.read_csv(data_folder+'y_test.csv').to_numpy()\n",
    "# y_val = pd.read_csv(data_folder+'y_val.csv').to_numpy()\n",
    "\n",
    "n_samples = 20\n",
    "\n",
    "X_train = pd.read_csv(data_folder+'X_train.csv').sample(n_samples)\n",
    "X_test = pd.read_csv(data_folder+'X_test.csv').sample(n_samples)\n",
    "X_val = pd.read_csv(data_folder+'X_val.csv').sample(n_samples)\n",
    "\n",
    "y_train = pd.read_csv(data_folder+'y_train.csv').sample(n_samples).to_numpy()\n",
    "y_test = pd.read_csv(data_folder+'y_test.csv').sample(n_samples).to_numpy()\n",
    "y_val = pd.read_csv(data_folder+'y_val.csv').sample(n_samples).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to convert bytecode to RGB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bytecode_to_rgb(bytecode):\n",
    "    rgb_code = []\n",
    "    for i in range(0, len(bytecode), 6):\n",
    "        segment = bytecode[i:i+6]\n",
    "        while len(segment) < 6:  # Pad with zeros if not of length 6\n",
    "            segment += '0'\n",
    "        # Replace known non-hexadecimal characters\n",
    "        segment = segment.replace('__', '00').replace('$f', 'ff')\n",
    "        # Replace any other non-hexadecimal characters\n",
    "        segment = ''.join([char if char in '0123456789abcdef' else '0' for char in segment.lower()])\n",
    "        r = int(segment[0:2], 16)\n",
    "        g = int(segment[2:4], 16)\n",
    "        b = int(segment[4:6], 16)\n",
    "        rgb_code.append((r, g, b))\n",
    "    return rgb_code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create an image from RGB code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image(rgb_code, image_size):\n",
    "    image = np.zeros((image_size, image_size, 3), dtype=np.uint8)\n",
    "    idx = 0\n",
    "    for i in range(image_size):\n",
    "        for j in range(image_size):\n",
    "            if idx < len(rgb_code):\n",
    "                image[i, j] = rgb_code[idx]\n",
    "                idx += 1\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytecode_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['BYTECODE'] = X_train['BYTECODE'].str.replace(' ', '').str.slice(0, bytecode_length)\n",
    "X_test['BYTECODE'] = X_test['BYTECODE'].str.replace(' ', '').str.slice(0, bytecode_length)\n",
    "X_val['BYTECODE'] = X_val['BYTECODE'].str.replace(' ', '').str.slice(0, bytecode_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy().squeeze()\n",
    "X_test = X_test.to_numpy().squeeze()\n",
    "X_val = X_val.to_numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rgb_code = bytecode_to_rgb(self.X[idx])\n",
    "        image = create_image(rgb_code, 224)\n",
    "        image = PIL.Image.fromarray(image)  # Convert numpy array to PIL Image\n",
    "        \n",
    "        # # Save the image to a folder\n",
    "        # folder = \"images\"  # Specify the folder name\n",
    "        # os.makedirs(folder, exist_ok=True)  # Create the folder if it does not exist\n",
    "        # filename = f\"{idx}.jpg\"  # Specify the file name\n",
    "        # filepath = os.path.join(folder, filename)  # Join the folder and file name\n",
    "        # image.save(filepath)  # Save the image\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to fit AlexNet input size\n",
    "    transforms.ToTensor(),  # Convert PIL Image to Torch Tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(X_train, y_train, transform=transform)\n",
    "val_dataset = MyDataset(X_val, y_val, transform=transform)\n",
    "test_dataset = MyDataset(X_test, y_test, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining some key variables that will be used later on in the training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 8\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-04\n",
    "num_class = 4\n",
    "labels = ['Timestamp dependence', 'Outdated Solidity version',\n",
    "          'Frozen Ether', 'Delegatecall Injection']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=VALID_BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=VALID_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tvaa8kYuQ_FT"
   },
   "source": [
    "## Create model and fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_misclassified_data(labels, preds, indices):\n",
    "    misclassify_data = {}\n",
    "    for i in range(len(labels)):\n",
    "        is_append = False\n",
    "        reject_label = np.array(labels[i])\n",
    "        for j in range(len(labels[i])):\n",
    "            if labels[i, j] != preds[i, j]:\n",
    "                reject_label[j] = 2  # reject label\n",
    "                is_append = True\n",
    "\n",
    "        if is_append:\n",
    "            x_train_index = indices[i]\n",
    "            misclassify_data[x_train_index] = np.array(reject_label)\n",
    "    return misclassify_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_steps(training_loader, model, loss_f, optimizer):\n",
    "    print('Training...')\n",
    "    training_loss = 0\n",
    "    nb_tr_steps = 0\n",
    "    train_acc = 0.\n",
    "    misclassify_train_data = {}\n",
    "    model.train()\n",
    "\n",
    "    total_samples_processed = 0  # Add this line\n",
    "\n",
    "    for i, (images, labels) in enumerate(training_loader):\n",
    "        # push the batch to gpu\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        labels = labels.to(device).float()\n",
    "        loss = loss_f(outputs, labels)\n",
    "        training_loss += loss.item()\n",
    "\n",
    "        # Convert outputs to probabilities\n",
    "        probabilities = torch.sigmoid(outputs)\n",
    "        \n",
    "        # Convert probabilities to binary predictions\n",
    "        max_indices = (probabilities >= 0.5).float()\n",
    "        max_indices = max_indices.detach().cpu().numpy()\n",
    "        label_ids = labels.to('cpu').numpy()\n",
    "\n",
    "        acc_score = accuracy_score(label_ids, max_indices)\n",
    "        train_acc += acc_score\n",
    "\n",
    "        # Generate indices for this batch\n",
    "        batch_size = len(images)\n",
    "        indices = list(range(total_samples_processed, total_samples_processed + batch_size))\n",
    "\n",
    "        misclassify_data = get_misclassified_data(label_ids, max_indices, indices)\n",
    "        misclassify_train_data.update(misclassify_data)\n",
    "\n",
    "        total_samples_processed += batch_size  # Update the total number of samples processed\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = training_loss / nb_tr_steps\n",
    "    epoch_acc = train_acc / nb_tr_steps\n",
    "\n",
    "    return epoch_loss, epoch_acc, misclassify_train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_steps(validating_loader, model, loss_f):\n",
    "    print(\"\\nEvaluating...\")\n",
    "\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "    total_labels = []\n",
    "    # iterate over batches\n",
    "    for i, (images, labels) in enumerate(validating_loader):\n",
    "        # push the batch to gpu\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "            # model predictions\n",
    "            outputs = model(images)\n",
    "\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = loss_f(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Convert outputs to probabilities\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            \n",
    "            # Convert probabilities to binary predictions\n",
    "            max_indices = (probabilities >= 0.5).float()\n",
    "            max_indices = max_indices.detach().cpu().numpy()\n",
    "            \n",
    "            total_preds += list(max_indices)\n",
    "            total_labels += labels.tolist()\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(validating_loader)\n",
    "    acc_score = accuracy_score(total_labels, total_preds)\n",
    "\n",
    "    return avg_loss, acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, model, optimizer, criterion, dataloader):\n",
    "    data_train_loader, data_val_loader = dataloader\n",
    "    # set initial loss to infinite\n",
    "    best_valid_loss = float('inf')\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_accuracies = []\n",
    "    valid_accuracies = []\n",
    "    misclassify_train_data = {}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {}/{} '.format(epoch + 1, epochs))\n",
    "        start_time = time.time()\n",
    "        train_loss, train_acc, misclassify_train_steps_data = train_steps(\n",
    "            data_train_loader, model, criterion, optimizer)\n",
    "        valid_loss, valid_acc = evaluate_steps(\n",
    "            data_val_loader, model, criterion)\n",
    "\n",
    "        # save the best model\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'secbert-escort.pt')\n",
    "        # append training and validation loss\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        valid_accuracies.append(valid_acc)\n",
    "        misclassify_train_data.update(misclassify_train_steps_data)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        print('\\t loss={:.4f} \\t accuracy={:.4f} \\t val_loss={:.4f}  \\t val_acc={:.4f}  \\t time={:.2f}s'.format(\n",
    "            train_loss, train_acc, valid_loss, valid_acc, elapsed_time))\n",
    "\n",
    "    return train_accuracies, valid_accuracies, train_losses, valid_losses, misclassify_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.alexnet(weights=AlexNet_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the last layer to match the number of classes in your dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): AlexNet(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Linear(in_features=4096, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier[6] = nn.Linear(4096, num_class)\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBA6dtJApX_a"
   },
   "source": [
    "### Creating the loss function and optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 \n",
      "Training...\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t loss=0.6359 \t accuracy=0.0000 \t val_loss=0.6581  \t val_acc=0.2000  \t time=1.84s\n"
     ]
    }
   ],
   "source": [
    "train_accuracies, valid_accuracies, train_losses, valid_losses, misclassify_train_data = train(EPOCHS, model, optimizer, criterion, (train_loader, val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save misclassified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(misclassify_train_data, orient='index', columns=[\n",
    "                            'Timestamp dependence', 'Outdated Solidity version', 'Frozen Ether', 'Delegatecall Injection'])\n",
    "df.index.name = 'X_train_index'\n",
    "df.to_csv(data_folder+'misclassified-data-alexnet.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the result of training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(epochs, train, valid, tittle):\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    plt.title(tittle)\n",
    "    plt.plot(list(np.arange(epochs) + 1), train, label='train')\n",
    "    plt.plot(list(np.arange(epochs) + 1), valid, label='validation')\n",
    "    plt.xlabel('num_epochs', fontsize=12)\n",
    "    plt.ylabel('loss', fontsize=12)\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(f\"{tittle}_secbert-alexnet.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(EPOCHS, train_losses, valid_losses, \"Train_Validation Loss\")\n",
    "plot_graph(EPOCHS, train_accuracies, valid_accuracies, \"Train_Validation Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XqDi7tjc9st"
   },
   "source": [
    "# EVALUATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(testing_loader, model):\n",
    "    print(\"\\nPredicting...\")\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "    total_labels = []\n",
    "    # iterate over batches\n",
    "    for i, (images, labels) in enumerate(testing_loader):\n",
    "        # push the batch to gpu\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "            # model predictions\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Convert outputs to probabilities\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            \n",
    "            # Convert probabilities to binary predictions\n",
    "            max_indices = (probabilities >= 0.5).float()\n",
    "            max_indices = max_indices.detach().cpu().numpy()\n",
    "            \n",
    "            total_preds += list(max_indices)\n",
    "            total_labels += labels.tolist()\n",
    "\n",
    "    return total_labels, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting...\n",
      "Predicting took 0.04 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()  # store the start time before calling predict\n",
    "# call predict and store the results\n",
    "total_labels, total_preds = predict(test_loader, model)\n",
    "end_time = time.time()  # store the end time after predict returns\n",
    "elapsed_time = end_time - start_time  # calculate the elapsed time in seconds\n",
    "# print the elapsed time in a formatted way\n",
    "print(f\"Predicting took {elapsed_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_classification(y_test, y_pred, out_dir, labels):\n",
    "    if isinstance(y_pred, np.ndarray) == False:\n",
    "        y_pred = y_pred.toarray()\n",
    "\n",
    "    def accuracy(y_true, y_pred):\n",
    "        temp = 0\n",
    "        for i in range(y_true.shape[0]):\n",
    "            numerator = sum(np.logical_and(y_true[i], y_pred[i]))\n",
    "            denominator = sum(np.logical_or(y_true[i], y_pred[i]))\n",
    "            if denominator != 0:\n",
    "                temp += numerator / denominator\n",
    "        return temp / y_true.shape[0]\n",
    "\n",
    "    out = classification_report(\n",
    "        y_test, y_pred, output_dict=True, target_names=labels)\n",
    "    total_support = out['samples avg']['support']\n",
    "\n",
    "    mr = accuracy_score(y_test, y_pred)\n",
    "    acc = accuracy(y_test, y_pred)\n",
    "    hm = hamming_loss(y_test, y_pred)\n",
    "\n",
    "    out['Exact Match Ratio'] = {\n",
    "        'precision': mr, 'recall': mr, 'f1-score': mr, 'support': total_support}\n",
    "    out['Hamming Loss'] = {'precision': hm, 'recall': hm,\n",
    "                           'f1-score': hm, 'support': total_support}\n",
    "    out['Accuracy'] = {'precision': acc, 'recall': acc,\n",
    "                       'f1-score': acc, 'support': total_support}\n",
    "    out_df = pd.DataFrame(out).transpose()\n",
    "    print(out_df)\n",
    "\n",
    "    out_df.to_csv(out_dir)\n",
    "\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "fJ_ZuWaNwWgE",
    "outputId": "ac2b41f5-c89b-4792-a9d9-ef9442c9c40e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score  support\n",
      "Timestamp dependence        0.000000  0.000000  0.000000      7.0\n",
      "Outdated Solidity version   0.750000  1.000000  0.857143     15.0\n",
      "Frozen Ether                0.550000  1.000000  0.709677     11.0\n",
      "Delegatecall Injection      0.000000  0.000000  0.000000      7.0\n",
      "micro avg                   0.650000  0.650000  0.650000     40.0\n",
      "macro avg                   0.325000  0.500000  0.391705     40.0\n",
      "weighted avg                0.432500  0.650000  0.516590     40.0\n",
      "samples avg                 0.650000  0.658333  0.635000     40.0\n",
      "Exact Match Ratio           0.150000  0.150000  0.150000     40.0\n",
      "Hamming Loss                0.350000  0.350000  0.350000     40.0\n",
      "Accuracy                    0.508333  0.508333  0.508333     40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bkcs/miniconda3/envs/secbert/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Timestamp dependence</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outdated Solidity version</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frozen Ether</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delegatecall Injection</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.391705</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.432500</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.516590</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exact Match Ratio</th>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hamming Loss</th>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           precision    recall  f1-score  support\n",
       "Timestamp dependence        0.000000  0.000000  0.000000      7.0\n",
       "Outdated Solidity version   0.750000  1.000000  0.857143     15.0\n",
       "Frozen Ether                0.550000  1.000000  0.709677     11.0\n",
       "Delegatecall Injection      0.000000  0.000000  0.000000      7.0\n",
       "micro avg                   0.650000  0.650000  0.650000     40.0\n",
       "macro avg                   0.325000  0.500000  0.391705     40.0\n",
       "weighted avg                0.432500  0.650000  0.516590     40.0\n",
       "samples avg                 0.650000  0.658333  0.635000     40.0\n",
       "Exact Match Ratio           0.150000  0.150000  0.150000     40.0\n",
       "Hamming Loss                0.350000  0.350000  0.350000     40.0\n",
       "Accuracy                    0.508333  0.508333  0.508333     40.0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_classification(y_test=np.array(total_labels), y_pred=np.array(\n",
    "    total_preds), labels=labels, out_dir='escort-secbert-max_lengt-Alexnet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'secBert_Alexnet.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
